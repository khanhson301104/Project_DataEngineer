import os
import json
import pandas as pd
from src.crawl_data.main_get_data import hanoi_gold_data, hcm_gold_data


def standardize_columns(df):
    """Chu·∫©n h√≥a t√™n c·ªôt"""
    column_mapping = {
        "Lo·∫°i v√†ng": "LOAIVANG",
        "Gi√° mua": "GIAMUA",
        "Gi√° b√°n": "GIABAN",
        "Date": "NGAY",
        "Th√†nh Ph·ªë": "THANHPHO"
    }

    # ƒê·ªïi t√™n c·ªôt n·∫øu c√≥
    df_copy = df.copy()
    for old_col, new_col in column_mapping.items():
        if old_col in df_copy.columns:
            df_copy = df_copy.rename(columns={old_col: new_col})

    # ƒê·∫£m b·∫£o c√≥ ƒë·ªß c√°c c·ªôt c·∫ßn thi·∫øt
    required_cols = ["LOAIVANG", "GIAMUA", "GIABAN", "NGAY", "THANHPHO"]
    for col in required_cols:
        if col not in df_copy.columns:
            df_copy[col] = ""

    return df_copy[required_cols]


def main():
    # Chu·∫©n h√≥a d·ªØ li·ªáu m·ªõi
    print("Chu·∫©n h√≥a d·ªØ li·ªáu m·ªõi...")
    hcm_standardized = standardize_columns(hcm_gold_data)
    hanoi_standardized = standardize_columns(hanoi_gold_data)

    # G·ªôp d·ªØ li·ªáu m·ªõi
    new_data = pd.concat([hcm_standardized, hanoi_standardized], ignore_index=True)
    print(f"D·ªØ li·ªáu m·ªõi: {len(new_data)} d√≤ng")

    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
    folder_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "temp_json_data")
    os.makedirs(folder_path, exist_ok=True)

    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file JSON
    json_file = os.path.join(folder_path, "gold_price_data.json")

    # X·ª≠ l√Ω d·ªØ li·ªáu c≈©
    if os.path.exists(json_file):
        print("ƒê·ªçc d·ªØ li·ªáu c≈©...")
        try:
            with open(json_file, "r", encoding="utf-8") as f:
                old_data_json = json.load(f)

            if old_data_json:  # Ki·ªÉm tra file kh√¥ng r·ªóng
                old_data = pd.DataFrame(old_data_json)
                old_data = standardize_columns(old_data)
                print(f"D·ªØ li·ªáu c≈©: {len(old_data)} d√≤ng")

                # G·ªôp d·ªØ li·ªáu c≈© v√† m·ªõi
                combined_df = pd.concat([old_data, new_data], ignore_index=True)
            else:
                print("File c≈© r·ªóng, ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu m·ªõi")
                combined_df = new_data
        except (json.JSONDecodeError, ValueError) as e:
            print(f"L·ªói ƒë·ªçc file c≈©: {e}. S·ª≠ d·ª•ng d·ªØ li·ªáu m·ªõi")
            combined_df = new_data
    else:
        print("Kh√¥ng c√≥ file c≈©, t·∫°o m·ªõi")
        combined_df = new_data

    print(f"T·ªïng d·ªØ li·ªáu tr∆∞·ªõc x·ª≠ l√Ω: {len(combined_df)} d√≤ng")

    # Lo·∫°i b·ªè d·ªØ li·ªáu null tr∆∞·ªõc khi x·ª≠ l√Ω tr√πng l·∫∑p
    combined_df = combined_df.dropna(subset=["LOAIVANG", "GIAMUA", "GIABAN", "NGAY", "THANHPHO"])
    print(f"Sau khi lo·∫°i b·ªè null: {len(combined_df)} d√≤ng")

    # X·ª≠ l√Ω tr√πng l·∫∑p (gi·ªØ b·∫£n ghi m·ªõi nh·∫•t)
    initial_count = len(combined_df)
    combined_df = combined_df.drop_duplicates(
        subset=["LOAIVANG", "GIAMUA", "GIABAN", "NGAY", "THANHPHO"],
        keep='last'  # Gi·ªØ b·∫£n ghi cu·ªëi (m·ªõi nh·∫•t)
    )
    removed_duplicates = initial_count - len(combined_df)
    print(f"ƒê√£ lo·∫°i b·ªè {removed_duplicates} b·∫£n ghi tr√πng l·∫∑p")
    print(f"D·ªØ li·ªáu cu·ªëi c√πng: {len(combined_df)} d√≤ng")

    # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu ƒë·ªÉ ghi kh√¥ng
    if len(combined_df) == 0:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ghi!")
        return

    # Ghi d·ªØ li·ªáu
    try:
        # S·∫Øp x·∫øp theo ng√†y ƒë·ªÉ d·ªØ li·ªáu c√≥ th·ª© t·ª±
        if 'NGAY' in combined_df.columns:
            combined_df = combined_df.sort_values('NGAY', ascending=False)

        combined_df.to_json(json_file, orient="records", force_ascii=False, indent=4)
        print(f"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng t·∫°i: {json_file}")
        print(f"üìä T·ªïng s·ªë b·∫£n ghi: {len(combined_df)}")

        # Hi·ªÉn th·ªã th·ªëng k√™
        if 'THANHPHO' in combined_df.columns:
            city_stats = combined_df['THANHPHO'].value_counts()
            print("üìç Th·ªëng k√™ theo th√†nh ph·ªë:")
            for city, count in city_stats.items():
                print(f"   - {city}: {count} b·∫£n ghi")

    except Exception as e:
        print(f"‚ùå L·ªói khi ghi JSON: {e}")

        # Ph∆∞∆°ng ph√°p d·ª± ph√≤ng
        print("üîÑ Th·ª≠ ph∆∞∆°ng ph√°p d·ª± ph√≤ng...")
        try:
            data_dict = []
            for _, row in combined_df.iterrows():
                record = {
                    "LOAIVANG": str(row["LOAIVANG"]) if pd.notna(row["LOAIVANG"]) else "",
                    "GIAMUA": str(row["GIAMUA"]) if pd.notna(row["GIAMUA"]) else "",
                    "GIABAN": str(row["GIABAN"]) if pd.notna(row["GIABAN"]) else "",
                    "NGAY": str(row["NGAY"]) if pd.notna(row["NGAY"]) else "",
                    "THANHPHO": str(row["THANHPHO"]) if pd.notna(row["THANHPHO"]) else ""
                }
                data_dict.append(record)

            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(data_dict, f, ensure_ascii=False, indent=4)
            print(f"‚úÖ ƒê√£ ghi d·ªØ li·ªáu b·∫±ng ph∆∞∆°ng ph√°p d·ª± ph√≤ng t·∫°i: {json_file}")
        except Exception as backup_error:
            print(f"‚ùå Ph∆∞∆°ng ph√°p d·ª± ph√≤ng c≈©ng th·∫•t b·∫°i: {backup_error}")


if __name__ == "__main__":
    main()